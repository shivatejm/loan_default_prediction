For dimensionality reduction of this huge dataset (88739 observations 75 features) we initially segregated the variables into both numerical and factor variables. The numerical variables were first fitted with Linear Regression to see which numerical features were important. The factor variables were chosen from Exploratory data analysis. After feature selection and omitting NA values, the data set came out to be 2,50,000*14 with only 14 features. This was randomly split into training(75%) and test data(25%) which was used for further analysis.	

Next came the best model selection. We fitted the Training data with various models like Logistic Regression, KNN, LDA and Random Forests. The key of the project is evaluating the importance of choosing the optimum threshold for Logistic Regression and Optimum value of K for KNN classifier. We let the data speak the best values of threshold and optimal value of K .For finding the optimum threshold, we found the predicted probabilities of  all the points in the test set. Now we varied the threshold between mean(predictedprobabilities)+0.01*std(predictedprobabilities) to mean(predictedprobabilities)+6*std(predictedprobabilities). The best threshold for Logistic came out to be Mean+3.19*st which is Optimum threshold value of  0.89 which gave the best accuracy of 82.29%. The best value of K which gave the highest accuracy was run by fitting the classifier for different values of K and the best value of K came out to be 36 and accuracy was 82.14%. 

The best classifier after healing the data came to be logistic regression with a threshold of 0.89. That is you give us a personâ€™s details and we will put it in our model and give you the probability p. if the probability p is greater than >0.89 that person is a defaulter.

Project motivation/background:
Credit risk analysis (finance risk analysis, loan default risk analysis) and credit risk management is important to financial institutions which provide loans to businesses and individuals. Credit can occur for various reasons: bank mortgages (or home loans), motor vehicle purchase finances, credit card purchases, installment purchases, and so on. Credit loans and finances have risk of being defaulted or delinquent. To understand risk levels of credit users, credit providers normally collect vast amount of information on borrowers. Statistical predictive analytic techniques can be used to analyze or to determine risk levels involved on credits, finances, and loans, i.e., default risk levels. Credit risk predictive modeling using Machine Learning methods is one of the prior priorities to banks like Chase, Bank of America etc. Here in the project we discuss about using Classification techniques to predict whether a person is defaulting or fully paying back the loan. We use different classifiers like KNN,Logisitc Regression, LDA and Random Forests to check which model fits our data well.
The key of the project is evaluating the importance of choosing the optimum threshold for Logistic Regression and Optimum value of K for KNN classifier. We let the data speak the best values of threshold and optimal value of K .For finding the optimum threshold, we found the predicted probabilities of  all the points in the test set. Now we varied the threshold between mean(predictedprobabilities)+0.01*std(predictedprobabilities) to mean(predictedprobabilities)+6*std(predictedprobabilities). The best threshold for Logistic came out to be Mean+3.19*st which is Optimum threshold value of  0.89 which gave the best accuracy of 82.29%. The best value of K which gave the highest accuracy was run by fitting the classifier for different values of K and the best value of K came out to be 36 and accuracy was 82.14%.
